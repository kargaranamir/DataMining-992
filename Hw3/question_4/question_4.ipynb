{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "practical-reminder",
   "metadata": {},
   "source": [
    "## Import and download libraries, model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compound-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gensim\n",
    "# ! pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latin-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.base import *\n",
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sorted-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorrect-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('entire_library_have_fun.csv')\n",
    "df = df[['Track Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-livestock",
   "metadata": {},
   "source": [
    "## clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compressed-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(get_stop_words('en'))\n",
    "nltk_words = list(stopwords.words('english'))\n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower() #lowercase\n",
    "    text = re.sub(r'\\bid\\b', 'i would', text) #start abbreviation\n",
    "    text = re.sub(r'\\bive\\b', 'i have', text)\n",
    "    text = re.sub(r'\\bim\\b', 'i am', text)\n",
    "    text = re.sub(r'\\bcant\\b', 'can not', text)\n",
    "    text = re.sub(r'\\bdont\\b', 'do not', text)\n",
    "    text = re.sub(r'\\bwont\\b', 'will not', text)\n",
    "    text = re.sub(r'\\bthats\\b', 'that is', text) #end abbreviation\n",
    "    text = re.sub('[0-9]+', '', text) # delete numbers\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text) #remove non-ascii\n",
    "    text = re.sub('[<>{}=~.,،:\\\\!?\\\\-()\\\\[\\\\]#/@\"]+|[_x000D_]+|\\u200c+|[\\r\\n]', ' ', text) #remove punctuations\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    word_list = list(filter(lambda word: word not in stop_words, word_list)) # delete stopwords\n",
    "    word_list = [w for w in word_list if len(w)>1] # delete len = 1\n",
    "    text = ' '.join(word_list)\n",
    "    text = text.strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pregnant-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned Track Name'] = df['Track Name'].apply(lambda x: clean(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-music",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "absent-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 300\n",
    "b = 10\n",
    "f = 100\n",
    "k = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-fellowship",
   "metadata": {},
   "source": [
    "## LSH Model and Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "royal-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_model_song = LSHIndex(f, b, d)\n",
    "\n",
    "sentence_vector_map = {}\n",
    "\n",
    "for index, value in enumerate(df['Cleaned Track Name']):\n",
    "    vectors = []\n",
    "    for word in value.split():\n",
    "        try:\n",
    "            vector = glove_model.get_vector(word)\n",
    "            if vector is not None:\n",
    "                vectors.append(vector)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if vectors:   \n",
    "        x = np.array(sum(vectors)/len(vectors))\n",
    "        sentence_vector_map[str(np.array([x]))] = value\n",
    "        lsh_model_song.index(index, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-opportunity",
   "metadata": {},
   "source": [
    "## Query over 'end of world'\n",
    "### top 3 similarities:\n",
    "-  Track names list: ['World’s About To End'] Similarity: 0.99999994\n",
    "-  Track names list: ['My World', 'The World Is Yours', 'The World', 'The World', 'World', 'My World'] Similarity: 0.8698745\n",
    "-  Track names list: ['Half the World'] Similarity: 0.85235816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "collected-sociology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\" Track names list: ['Big World'] Similarity: [[0.81706697]]\",\n",
       " \" Track names list: ['End of Time', 'End Of Time'] Similarity: [[0.8323111]]\",\n",
       " \" Track names list: ['Half the World'] Similarity: [[0.85235816]]\",\n",
       " \" Track names list: ['Let The World Turn'] Similarity: [[0.7884188]]\",\n",
       " \" Track names list: ['My World', 'The World Is Yours', 'The World', 'The World', 'World', 'My World'] Similarity: [[0.8698745]]\",\n",
       " \" Track names list: ['New World'] Similarity: [[0.8213221]]\",\n",
       " \" Track names list: ['Night of Blood in a World Without End'] Similarity: [[0.8081635]]\",\n",
       " \" Track names list: ['Not With All the Hope in the World'] Similarity: [[0.8420321]]\",\n",
       " \" Track names list: ['The Day The World Went Away', 'The Day The World Went Away', 'The Day The World Went Away', 'The Day The World Went Away', 'The Day The World Went Away'] Similarity: [[0.79932874]]\",\n",
       " \" Track names list: ['World’s About To End'] Similarity: [[0.99999994]]\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = 'end of world'\n",
    "vectors = []\n",
    "clean_value = clean('end of world')\n",
    "for word in clean_value.split():\n",
    "    try:\n",
    "        vector = glove_model.get_vector(word)\n",
    "        if vector is not None:\n",
    "            vectors.append(vector)\n",
    "    except:\n",
    "        pass\n",
    "if vectors:   \n",
    "    q = np.array([np.array(sum(vectors)/len(vectors))])\n",
    "\n",
    "results = lsh_model_song.query(q, k)\n",
    "\n",
    "set_results = set()\n",
    "for i in results:\n",
    "    sentence = sentence_vector_map[str(i)]\n",
    "    track_names = list(df[df['Cleaned Track Name'] == sentence]['Track Name'])\n",
    "    similarity = 1 - cosine_distance(i,q)\n",
    "    set_results.add(f\" Track names list: {track_names} Similarity: {similarity}\")\n",
    "set_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-orange",
   "metadata": {},
   "source": [
    "## Query over 'he and his friend'\n",
    "### top 3 similarities:\n",
    "- Track names list: ['What a Friend', 'Friend To All', 'Friend', 'Only Friend'] Similarity: 1\n",
    "- Track names list: ['Friend of the Night'] Similarity: 0.81013167\n",
    "- Track names list: ['All My Friends', 'Friends', 'All My Friends'] Similarity: 0.7554451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "coupled-paradise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\" Track names list: ['All My Friends', 'Friends', 'All My Friends'] Similarity: [[0.7554451]]\",\n",
       " \" Track names list: ['Another Girl'] Similarity: [[0.51693785]]\",\n",
       " \" Track names list: ['Danny Boy'] Similarity: [[0.49132073]]\",\n",
       " \" Track names list: ['Family Song for the Leaving'] Similarity: [[0.5208501]]\",\n",
       " \" Track names list: ['Fortunate Son - Live'] Similarity: [[0.4717186]]\",\n",
       " \" Track names list: ['Friend of the Night'] Similarity: [[0.81013167]]\",\n",
       " \" Track names list: ['Half Sister'] Similarity: [[0.46893597]]\",\n",
       " \" Track names list: ['Hello, Good Night'] Similarity: [[0.47629404]]\",\n",
       " \" Track names list: ['Killing Your Love'] Similarity: [[0.4923262]]\",\n",
       " \" Track names list: ['Not Even Married'] Similarity: [[0.5281723]]\",\n",
       " \" Track names list: ['Not a Daughter', 'Daughter'] Similarity: [[0.59166664]]\",\n",
       " \" Track names list: ['The Night Me and Your Mama Met'] Similarity: [[0.4992473]]\",\n",
       " \" Track names list: ['The Poet You Never Were'] Similarity: [[0.54257655]]\",\n",
       " \" Track names list: ['What a Friend', 'Friend To All', 'Friend', 'Only Friend'] Similarity: [[1.]]\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = 'he and his friend'\n",
    "vectors = []\n",
    "clean_value = clean('he and his friend')\n",
    "for word in clean_value.split():\n",
    "    try:\n",
    "        vector = glove_model.get_vector(word)\n",
    "        if vector is not None:\n",
    "            vectors.append(vector)\n",
    "    except:\n",
    "        pass\n",
    "if vectors:   \n",
    "    q = np.array([np.array(sum(vectors)/len(vectors))])\n",
    "\n",
    "results = lsh_model_song.query(q, k)\n",
    "\n",
    "set_results = set()\n",
    "for i in results:\n",
    "    sentence = sentence_vector_map[str(i)]\n",
    "    track_names = list(df[df['Cleaned Track Name'] == sentence]['Track Name'])\n",
    "    similarity = 1 - cosine_distance(i,q)\n",
    "    set_results.add(f\" Track names list: {track_names} Similarity: {similarity}\")\n",
    "set_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
